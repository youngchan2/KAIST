{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f912c23d",
      "metadata": {
        "id": "f912c23d"
      },
      "source": [
        "In the second part of this assignment, we will implement support vector machine and kernel support vector machine."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ed8691",
      "metadata": {
        "id": "d9ed8691"
      },
      "source": [
        "## **Preparation**\n",
        "The following code is the preparation for importing packages. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aae0c5d9",
      "metadata": {
        "id": "aae0c5d9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cvxopt as cvx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e15341e",
      "metadata": {
        "id": "4e15341e"
      },
      "source": [
        "## **[Step 1-3] Soft margin support vector machine (SVM) implementation**\n",
        "\n",
        "In this assignment, you should use only NumPy to build the SVM models.\n",
        "\n",
        "**DO NOT** use other libraries to implement the SVM models.\n",
        "\n",
        "**DO NOT** modify other parts of the skeleton code.\n",
        "\n",
        "Follow the comments. They'll give you instructions on what to code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf6d1f5",
      "metadata": {
        "id": "caf6d1f5"
      },
      "source": [
        "### Step 1. Build the soft margin SVM models based on the gradient descent\n",
        "The followings are the skeleton codes. Implement the functions inside the ```SVM``` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c5ab06",
      "metadata": {
        "id": "a3c5ab06"
      },
      "outputs": [],
      "source": [
        "class SVM():\n",
        "    def __init__(self, X_data, reg=1):\n",
        "        # Initialize the model parameters as the instance variable.\n",
        "        print(\"-\"*50, \"\\nInitialize the parameters of our SVM.\\n\")\n",
        "        self.W = np.random.randn(X_data.shape[1])\n",
        "        self.w_0 = np.random.randn(1)\n",
        "        self.reg = reg\n",
        "    \n",
        "    # Function for calculating the loss.\n",
        "    def objective_function(self, X_data, y_label):\n",
        "        # Define the objective function for the SVM classifier.\n",
        "        distance = 1 - y_label * (X_data.dot(self.W) + self.w_0)\n",
        "        distance[distance < 0] = 0.\n",
        "        cost = 1/2 * self.reg * self.W.T.dot(self.W) + np.sum(distance, axis=0) / X_data.shape[0]\n",
        "        return cost\n",
        "    \n",
        "    # Function for calculating the gradient \n",
        "    def calculate_gradient(self, X_data, y_label):\n",
        "        # Compute the gradient of W and w_0 from the entire epoch.\n",
        "        distance = np.sign(1 - y_label * (X_data.dot(self.W) + self.w_0))\n",
        "        distance[distance < 0] = 0.\n",
        "        gradient_W = self.reg * self.W - np.sum((X_data.T * y_label * distance).T, axis=0) / X_data.shape[0]\n",
        "        gradient_w_0 = -np.sum(y_label * distance, axis=0) / X_data.shape[0]\n",
        "                \n",
        "        return gradient_W, gradient_w_0\n",
        "    \n",
        "    # Function for training\n",
        "    def train(self, x_input, y_label, lr=0.01, epochs=50):\n",
        "        # Update the model parameters (W, w_0) using the above calculate_gradient function.\n",
        "        print(\"- Total Epochs \\t\\t: \", epochs)\n",
        "        print(\"- Learning rate \\t: \", lr)\n",
        "        print(\"-\"*50)\n",
        "        for epoch in range(epochs):\n",
        "            cost = self.objective_function(x_input, y_label)\n",
        "            gradient_W, gradient_w_0 = self.calculate_gradient(x_input, y_label)\n",
        "            self.W += -1 * lr * gradient_W\n",
        "            self.w_0 += -1 * lr * gradient_w_0\n",
        "            if epoch % 10 == 0:\n",
        "                print(\"[Epoch : %d/%d]\\t\\t| Cost: %.4f\"%(epoch+10, epochs, cost))\n",
        "        print(\"-\"*50, \"\\nLearning is complete.\\n\")\n",
        "        print(\"- W \\t:\", self.W)\n",
        "        print(\"- W_0 \\t:\", self.w_0)\n",
        "\n",
        "    # Function for prediction\n",
        "    def predict(self, x_input):\n",
        "        # Compute our SVM prediction, and transform it into the binary label.\n",
        "        result = np.sign(x_input.dot(self.W) + self.w_0)\n",
        "        return result\n",
        "    \n",
        "    # Function for evaluation\n",
        "    def accuracy(self, predict, y_label):\n",
        "        result = np.sum(predict == y_label) / len(predict)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0ad48bc",
      "metadata": {
        "id": "f0ad48bc"
      },
      "source": [
        "### Step 2. Load the dataset 1\n",
        "The dataset is the isotropic Gaussian blobs with noise for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DYTToDtRXIdn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYTToDtRXIdn",
        "outputId": "09752006-6e66-4cbb-8751-1d1c5ac64feb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785ad63c",
      "metadata": {
        "id": "785ad63c"
      },
      "outputs": [],
      "source": [
        "# Load the train, validation, test dataset.\n",
        "train = np.load(\"./drive/MyDrive/Dataset1(Train).npy\")\n",
        "validation = np.load(\"./drive/MyDrive/Dataset1(Validation).npy\")\n",
        "test = np.load(\"./drive/MyDrive/Dataset1(Test).npy\")\n",
        "\n",
        "# Set the X, y data for each dataset. \n",
        "X_train = train[:, :-1]\n",
        "y_train = train[:, -1]\n",
        "\n",
        "X_val = validation[:, :-1]\n",
        "y_val = validation[:, -1]\n",
        "\n",
        "X_test = test[:, :-1]\n",
        "y_test = test[:, -1]\n",
        "\n",
        "# Visualize the train dataset.\n",
        "fig = plt.figure(figsize=(9, 6), dpi=100)\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot(X_train[:, 0][y_train == -1], X_train[:, 1][y_train == -1], X_train[:, 2][y_train == -1], '.', label=\"Class 1\")\n",
        "ax.plot(X_train[:, 0][y_train == 1], X_train[:, 1][y_train == 1], X_train[:, 2][y_train == 1], '.', label=\"Class 2\")\n",
        "plt.title(\"The 3D plot of the train dataset\", fontsize=17)\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.set_zlabel('Feature 3')\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6296c4ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6296c4ac",
        "outputId": "94da8279-095b-42d4-a1e9-806c59739821"
      },
      "outputs": [],
      "source": [
        "# Check the size of each dataset.\n",
        "print(\"The shape of the train dataset\\t\\t: %s\\t | The shape of train label\\t\\t: %s\"%(X_train.shape, y_train.shape))\n",
        "print(\"The shape of the validation dataset\\t: %s\\t | The shape of validation label\\t: %s\"%(X_val.shape, y_val.shape))\n",
        "print(\"The shape of the test dataset\\t\\t: %s\\t | The shape of test label\\t\\t: %s\"%(X_test.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61cc68fc",
      "metadata": {
        "id": "61cc68fc"
      },
      "source": [
        "### Step 3. Train and test the soft margin SVM models with different learning rates.\n",
        "Check the tendency of the loss value that changes with the different learning rates. Visualize the result of the SVM models with the different learning rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b4f551",
      "metadata": {
        "id": "f9b4f551",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(111)\n",
        "\n",
        "# Set variables(hyperparameters) to train our SVM model.\n",
        "lr = 1e-4\n",
        "epochs = 100\n",
        "reg = 1\n",
        "\n",
        "train_setting = {\"lr\": [1e-2, 1e-3]}\n",
        "models = []\n",
        "for i, lr in enumerate(train_setting[\"lr\"]):\n",
        "    # Build our SVM model.\n",
        "    model = SVM(X_train, reg)\n",
        "    # Start train our SVM model.\n",
        "    model.train(X_train, y_train, lr=lr, epochs=epochs)\n",
        "\n",
        "    # Predict the results using our trained SVM model.\n",
        "    train_predicted = model.predict(X_train)\n",
        "    # Compute the accuracy of prediction for the train set\n",
        "    acc = model.accuracy(train_predicted, y_train)\n",
        "    print(\"\\n- The accuracy of the train set \\t: %.3f\"%acc)\n",
        "\n",
        "    val_predicted = model.predict(X_val)\n",
        "    acc = model.accuracy(val_predicted, y_val)\n",
        "    print(\"- The accuracy of the validation set \\t: %.3f\"%acc)\n",
        "    print(\"-\"*50,\"\\n\")\n",
        "    models.append((model, lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97178b0e",
      "metadata": {
        "id": "97178b0e"
      },
      "source": [
        "#### Visualize a trained SVM model (idx-th) with the 3D plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f50b0c19",
      "metadata": {
        "id": "f50b0c19"
      },
      "outputs": [],
      "source": [
        "# Visualize a trained SVM model (idx-th) with the 3D plot\n",
        "idx = 0\n",
        "model = models[idx]\n",
        "\n",
        "test_predicted = model[0].predict(X_test)\n",
        "acc = model[0].accuracy(test_predicted, y_test)\n",
        "print(\"- The accuracy of prediction for the test set \\t:\", acc)\n",
        "\n",
        "# Set the axis to generate the meshgrid axis\n",
        "x_axis = np.arange(-50, 100, 1)\n",
        "y_axis = np.arange(-50, 100, 1)\n",
        "x_axis, y_axis = np.meshgrid(x_axis, y_axis)\n",
        "\n",
        "# Define the hyper plane, and then visualize it. \n",
        "Z = - (x_axis * model[0].W[0] + y_axis * model[0].W[1] + model[0].w_0)/model[0].W[2]\n",
        "fig = plt.figure(figsize=(9, 6), dpi=100)\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot the linearly separable sample datasets with the predicted labels.\n",
        "ax.plot(X_test[:, 0][y_test == -1], X_test[:, 1][y_test == -1], X_test[:, 2][y_test == -1], '.', label=\"Class 1\")\n",
        "ax.plot(X_test[:, 0][y_test == 1], X_test[:, 1][y_test == 1], X_test[:, 2][y_test == 1], '.', label=\"Class 2\")\n",
        "label = \"Hyperplane\"\n",
        "plane = ax.plot_surface(x_axis, y_axis, Z, label = label)\n",
        "plane._facecolors2d = plane._facecolor3d\n",
        "plane._edgecolors2d = plane._edgecolor3d\n",
        "\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.set_zlabel('Feature 3')\n",
        "ax.view_init(25,-90)\n",
        "ax.grid()\n",
        "ax.legend(loc='lower left')\n",
        "plt.title(\"Test result of the SVM classification with lr=0.01\", fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad3a19e",
      "metadata": {
        "id": "1ad3a19e"
      },
      "outputs": [],
      "source": [
        "# Visualize a trained SVM model (idx-th) with the 3D plot\n",
        "idx = 1\n",
        "model = models[idx]\n",
        "\n",
        "test_predicted = model[0].predict(X_test)\n",
        "acc = model[0].accuracy(test_predicted, y_test)\n",
        "print(\"- The accuracy of prediction for the test set \\t:\",acc)\n",
        "\n",
        "# Set the axis to generate the meshgrid axis\n",
        "x_axis = np.arange(-50, 100, 1)\n",
        "y_axis = np.arange(-50, 100, 1)\n",
        "x_axis, y_axis = np.meshgrid(x_axis, y_axis)\n",
        "\n",
        "# Define the hyper plane, and then visualize it. \n",
        "Z = -(x_axis * model[0].W[0] + y_axis * model[0].W[1] + model[0].w_0) / model[0].W[2]\n",
        "fig = plt.figure(figsize=(9, 6), dpi=100)\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot the linearly separable sample datasets with the predicted labels.\n",
        "ax.plot(X_test[:, 0][y_test == -1], X_test[:, 1][y_test == -1], X_test[:, 2][y_test == -1], '.', label=\"Class 1\")\n",
        "ax.plot(X_test[:, 0][y_test == 1], X_test[:, 1][y_test == 1], X_test[:, 2][y_test == 1], '.', label=\"Class 2\")\n",
        "label = \"Hyperplane\"\n",
        "plane = ax.plot_surface(x_axis, y_axis, Z, label = label)\n",
        "plane._facecolors2d = plane._facecolor3d\n",
        "plane._edgecolors2d = plane._edgecolor3d\n",
        "\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.yaxis.set_ticklabels([])\n",
        "ax.set_zlabel('Feature 3')\n",
        "ax.view_init(1,90)\n",
        "ax.grid()\n",
        "ax.legend(loc='lower right')\n",
        "plt.title(\"Test result of the SVM classification with lr=0.001\", fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0164fd5",
      "metadata": {
        "id": "a0164fd5"
      },
      "source": [
        "## **[Step 4-6] Kernel SVM implementation**\n",
        "\n",
        "In this assignment, you should use only NumPy and CVXOPT to build the Kernel SVM models.\n",
        "\n",
        "**DO NOT** use other libraries to implement the Kernel SVM models.\n",
        "\n",
        "**DO NOT** modify other parts of the skeleton code.\n",
        "\n",
        "Follow the comments. They'll give you instructions on what to code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f60c15d",
      "metadata": {
        "id": "0f60c15d"
      },
      "source": [
        "### Step 4. Build the Kernel SVM models based on the dual form\n",
        "The followings are the skeleton codes. Implement the functions inside the ```kernels``` class and the ```Kernel_SVM```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f7428e0",
      "metadata": {
        "id": "5f7428e0"
      },
      "outputs": [],
      "source": [
        "class kernels: \n",
        "    # Function for computing the kernel matrix\n",
        "    def __init__(self, poly_c=10, poly_d=2, gamma=0.001):\n",
        "        self.poly_c = poly_c\n",
        "        self.poly_d = poly_d\n",
        "        self.gamma = gamma\n",
        "    \n",
        "    # Function for the polynomial kernel.\n",
        "    def polynomial_kernel(self, x, y, c=10, d=2):\n",
        "        # Implement the polynomial kernel function\n",
        "        result = (c + x.dot(y)) ** d\n",
        "        return result\n",
        "    \n",
        "    # Function for the gaussian kernel.\n",
        "    def gaussian_kernel(self, x, y, gamma=0.001):\n",
        "        # Implement the linear kernel function.\n",
        "        # Gamma means 1/(2*sigma**2) where sigma is a free parameter.\n",
        "        # It can be seen as the standard deviation of the gaussian distribution.\n",
        "        result = np.linalg.norm(np.array(x)-np.array(y), ord=None)**2\n",
        "        result = np.exp(-gamma*result)\n",
        "        return result\n",
        "\n",
        "# Function for computing the kernel matrix\n",
        "def compute_inner_matrix(X_data, kernel):\n",
        "    # Generate the kernel matrix using the kernel function.\n",
        "    n = X_data.shape[0]\n",
        "    inner_matrix = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            inner_matrix[i,j] = kernel(X_data[i], X_data[j])\n",
        "    return inner_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ebebb7",
      "metadata": {
        "id": "55ebebb7"
      },
      "outputs": [],
      "source": [
        "class Kernel_SVM:\n",
        "    def __init__(self, kernel, threshold_SV):\n",
        "        # Set the parameters as the hinstance variables.\n",
        "        self.kernel = kernel\n",
        "        self.threshold_SV = threshold_SV\n",
        "    \n",
        "    # Function for computing the lagrangian multiplier vector.\n",
        "    def compute_lagrange(self, X_data, y_label):\n",
        "        #Here we will use the cvxopt python library. We will use its matrix objects cvx.matrix\n",
        "        # Compute the kernel matrix using kernel function.\n",
        "        kernel_matrix = compute_inner_matrix(X_data, self.kernel)\n",
        "        \n",
        "        # Compute P matrix using y_label vectors and kernel_matrix.\n",
        "        P = cvx.matrix(np.outer(y_label, y_label) * kernel_matrix, tc='d')\n",
        "        # Set ones vector to compute the sum of the alpha vector.\n",
        "        q = cvx.matrix(-np.ones(X_data.shape[0]), tc='d')\n",
        "        \n",
        "        # Set the identity metrix for our inequality constraint \n",
        "        # that all elements of the alpha vector should be greater then equal to zero.\n",
        "        G = cvx.matrix(-np.identity(X_data.shape[0]), tc='d')\n",
        "        h = cvx.matrix(np.zeros(X_data.shape[0]), tc='d')\n",
        "        \n",
        "        # Set the y_label vector for our equality constraint\n",
        "        # that tha result of the multiplication of elements of the alpha and y_label vector should be zero. \n",
        "        A = cvx.matrix(y_label, (1, X_data.shape[0]), tc='d') \n",
        "        b = cvx.matrix(0.)\n",
        "        \n",
        "        # Compute the alpha vector.\n",
        "        alpha = np.array(cvx.solvers.qp(P, q, G, h, A, b)['x']).flatten()\n",
        "\n",
        "        return alpha\n",
        "\n",
        "    # Function for training.\n",
        "    def train(self,X_data, y_label):\n",
        "        # Compute the alpha vector using compute_lagrange function.\n",
        "        self.alpha = self.compute_lagrange(X_data, y_label)\n",
        "        \n",
        "        # Set the alpha values that are greater than the threshold.\n",
        "        self.alpha_support = self.alpha[self.alpha > self.threshold_SV]\n",
        "        # Set the support vectors corresponding to the value of alpha that is greater than the threshold.\n",
        "        self.support_vectors = X_data[np.argwhere(self.alpha > self.threshold_SV)].reshape(-1, X_data.shape[1])\n",
        "        # Set the labels of the support vectors corresponding to the alpha value that is greater than the threshold.\n",
        "        self.support_vectors_labels = y_label[np.argwhere(self.alpha > self.threshold_SV)]\n",
        "\n",
        "    # Function for prediction.\n",
        "    def predict(self,x_data):\n",
        "        # Compute our kernel SVM prediction, and transform it to the binary label.\n",
        "        # And then append it to the list.\n",
        "        y_pred = [] # It represents the predicted label of each data point,\n",
        "        pred = [] # it represents the output value of each data point. (without sign function)\n",
        "        for i in range(x_data.shape[0]):\n",
        "            # Comput the bias vector to predict the label of each data point.\n",
        "            self.bias = 0\n",
        "            for (alpha, x_, y_) in zip(self.alpha_support, self.support_vectors, self.support_vectors_labels):\n",
        "                # comput the output value of kernel SVM model.\n",
        "                self.bias += y_\n",
        "                self.bias = self.bias - np.sum(alpha * y_ * self.kernel(x_, x_data[i]))\n",
        "            self.bias /= len(self.alpha_support)\n",
        "            output = self.bias\n",
        "            for (alpha, x_, y_) in zip(self.alpha_support, self.support_vectors, self.support_vectors_labels):\n",
        "                # Compute the output value of our prediction \n",
        "                output += alpha * y_ * self.kernel(x_, x_data[i])\n",
        "            # Using sign function, transform our prediction to the binary label. \n",
        "            y_pred.extend(np.sign(output))\n",
        "            pred.extend(output)\n",
        "        \n",
        "        return y_pred, pred\n",
        "    \n",
        "    # Function for evaluation.\n",
        "    def accuracy(self, predict, y_label):\n",
        "        result = np.sum(predict == y_label) / len(predict)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d415c5cd",
      "metadata": {
        "id": "d415c5cd"
      },
      "source": [
        "### Step 5. Load the dataset 2\n",
        "The dataset is the  isotropic Gaussian blobs with noise for classification. Load the dataset and split it into the train and test set by executing the provided code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eebf62a5",
      "metadata": {
        "id": "eebf62a5"
      },
      "outputs": [],
      "source": [
        "# Load the train, validation, test dataset.\n",
        "train = np.load(\"./drive/MyDrive/Dataset2(Train).npy\")\n",
        "validation = np.load(\"./drive/MyDrive/Dataset2(Validation).npy\")\n",
        "test = np.load(\"./drive/MyDrive/Dataset2(Test).npy\")\n",
        "\n",
        "# Set the X, y data for each dataset. \n",
        "X_train = train[:, :-1]\n",
        "y_train = train[:, -1]\n",
        "X_val = validation[:, :-1]\n",
        "y_val = validation[:, -1]\n",
        "X_test = test[:, :-1]\n",
        "y_test = test[:, -1]\n",
        "\n",
        "# Visualize the train dataset.\n",
        "fig = plt.figure(figsize=(9, 6), dpi=100)\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(X_train[y_train == -1, 0], X_train[y_train == -1, 1], label=\"Class 1\") \n",
        "ax.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], label=\"Class 2\") \n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "plt.title(\"The 2D plot of the non-linearly separable sample dataset\", fontsize=17)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f9ec830",
      "metadata": {
        "id": "2f9ec830"
      },
      "outputs": [],
      "source": [
        "# Check the size of each dataset.\n",
        "print(\"The shape of the train dataset\\t\\t: %s\\t | The shape of train label\\t\\t: %s\"%(X_train.shape, y_train.shape))\n",
        "print(\"The shape of the validation dataset\\t: %s\\t | The shape of validation label\\t: %s\"%(X_val.shape, y_val.shape))\n",
        "print(\"The shape of the test dataset\\t\\t: %s\\t | The shape of test label\\t\\t: %s\"%(X_test.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c01c169f",
      "metadata": {
        "id": "c01c169f"
      },
      "source": [
        "### Step 6. Train and test the Kernel SVM models with different types of kernels\n",
        "Check the accuracy of the Kernel SVM model with different types of kernels.\n",
        "\n",
        "- The performance of **the Polynomial Kernel SVM models** varies depending on the kernel’s hyperparameters ```poly_c``` and ```poly_d```.\n",
        "- The performance of **the Gaussian Kernel SVM models** varies depending on the kernel’s hyperparameter ```gamma```."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f83997e",
      "metadata": {
        "id": "9f83997e"
      },
      "source": [
        "#### Train the Gaussian Kernel SVM model with the different hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df699e6d",
      "metadata": {
        "id": "df699e6d"
      },
      "outputs": [],
      "source": [
        "# Feel free to experiment with hyperparameters\n",
        "# Default values of the hyperparametes are as belows:\n",
        "gamma = 0.001\n",
        "\n",
        "utils_ = kernels(gamma=gamma)\n",
        "kernel = utils_.gaussian_kernel\n",
        "\n",
        "# Initialize the kernel SVM model, and then train it.\n",
        "Gaussian_kernel = Kernel_SVM(kernel=kernel, threshold_SV=10**(-3))\n",
        "Gaussian_kernel.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ab9b495",
      "metadata": {
        "id": "9ab9b495"
      },
      "source": [
        "#### Evaluate the Gaussian Kernel SVM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2a2e96",
      "metadata": {
        "id": "bd2a2e96"
      },
      "outputs": [],
      "source": [
        "# Predict the results using our trained SVM model.\n",
        "train_predicted, pred = Gaussian_kernel.predict(X_train)\n",
        "# Compute the accuracy of prediction for the train set\n",
        "acc = Gaussian_kernel.accuracy(train_predicted, y_train)\n",
        "print(\"- The accuracy of prediction for the train set \\t\\t:\",acc)\n",
        "\n",
        "val_predicted, pred = Gaussian_kernel.predict(X_val)\n",
        "acc = Gaussian_kernel.accuracy(val_predicted, y_val)\n",
        "print(\"- The accuracy of prediction for the validation set \\t:\",acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a56f499",
      "metadata": {
        "id": "1a56f499"
      },
      "source": [
        "#### Visualize the result of the Gaussian Kernel SVM classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1614b609",
      "metadata": {
        "id": "1614b609"
      },
      "outputs": [],
      "source": [
        "from matplotlib import cm\n",
        "Z, _ = Gaussian_kernel.predict(X_test)\n",
        "acc = Gaussian_kernel.accuracy(Z, y_test)\n",
        "print(\"- The accuracy of prediction for the test set \\t:\",acc)\n",
        "Z = np.array(Z)\n",
        "fig = plt.figure(figsize=(9, 6), dpi=100)\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.scatter(X_test[y_test == -1, 0], X_test[y_test == -1, 1], Z[y_test == -1], label=\"Class 1\") \n",
        "ax.scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], Z[y_test == 1], label=\"Class 2\")\n",
        "\n",
        "plt.title(\"The 3D plot of the test result of the kernel SVM classification\\n(Gaussian kernel: $\\gamma$ = 0.001)\", fontsize=13)\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.set_zlabel('Class label')\n",
        "ax.view_init(20,10)\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "209cebbc",
      "metadata": {
        "id": "209cebbc"
      },
      "source": [
        "#### Train the Polynomial Kernel SVM model with the different hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d11404fd",
      "metadata": {
        "id": "d11404fd",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Chose which kernel to use.\n",
        "# Feel free to experiment with hyperparameters\n",
        "# Default values of the hyperparametes are as belows:\n",
        "poly_c = 10\n",
        "poly_d = 2\n",
        "\n",
        "utils_ = kernels(poly_c=poly_c, poly_d=poly_d)\n",
        "kernel = utils_.polynomial_kernel\n",
        "\n",
        "# Initialize the kernel SVM model, and then train it.\n",
        "Polynomial_kernel = Kernel_SVM(kernel=kernel, threshold_SV=10**(-10))\n",
        "Polynomial_kernel.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a68bef04",
      "metadata": {
        "id": "a68bef04"
      },
      "source": [
        "#### Evaluate the Polynomial Kernel SVM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea68e72f",
      "metadata": {
        "id": "ea68e72f"
      },
      "outputs": [],
      "source": [
        "# Predict the results of the polynomial kernel SVM model.\n",
        "train_predicted, pred = Polynomial_kernel.predict(X_train)\n",
        "# Compute the accuracy of prediction for the train set\n",
        "acc = Polynomial_kernel.accuracy(train_predicted, y_train)\n",
        "print(\"- The accuracy of prediction for the train set \\t\\t:\",acc)\n",
        "\n",
        "val_predicted, pred = Polynomial_kernel.predict(X_val)\n",
        "acc = Polynomial_kernel.accuracy(val_predicted, y_val)\n",
        "print(\"- The accuracy of prediction for the validation set \\t:\",acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26d5c20",
      "metadata": {
        "id": "b26d5c20"
      },
      "source": [
        "#### Visualize the result of the Polynomial Kernel SVM classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8533da",
      "metadata": {
        "id": "bf8533da"
      },
      "outputs": [],
      "source": [
        "Z, _ = Polynomial_kernel.predict(X_test)\n",
        "acc = Polynomial_kernel.accuracy(Z, y_test)\n",
        "print(\"- The accuracy of prediction for the test set \\t:\",acc)\n",
        "Z = np.array(Z)\n",
        "fig = plt.figure(figsize=(9, 6), dpi=100)\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.scatter(X_test[y_test == -1, 0], X_test[y_test == -1, 1], Z[y_test == -1], label=\"Class 1\") \n",
        "ax.scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], Z[y_test == 1], label=\"Class 2\")\n",
        "\n",
        "plt.title(\"The 3D plot of the test result of the kernel SVM classification\\n(Polynomial kernel: c = 10, d = 2)\", fontsize=13)\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.set_zlabel('Class label')\n",
        "ax.view_init(20, 10)\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
